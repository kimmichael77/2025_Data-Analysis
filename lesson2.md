## 1. 회귀분석

### 1.1. 선형회귀

#### 1.1.1. 다중선형회귀를 행렬식으로 표현

```math
\boldsymbol y = \boldsymbol {X \beta} + \boldsymbol \epsilon 
```

이때, $\boldsymbol y$와 $\boldsymbol \epsilon$는 $(n \times 1)$, $\boldsymbol X$는 $(n \times p)$, $\boldsymbol \beta$는 $(p \times 1)$ 차원의 벡터와 행렬이며, $x_{11} = x_{21} = \cdots = x_{n1} = 1$는 절편항인 모형으로, 절편까지 포함한 변수의 개수가 $p$개, 관측치의 수는 $n$개이다.

```math
\boldsymbol y = \begin{pmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{pmatrix}

\qquad

\boldsymbol X = \begin{pmatrix}
x_{11} & x_{12} & \cdots & x_{1p} \\
x_{21} & x_{22} & \cdots & x_{2p} \\
&&\vdots \\
x_{n1} & x_{n2} & \cdots & x_{np} \\
\end{pmatrix}

\qquad

\boldsymbol \beta = \begin{pmatrix}
\beta_1 \\
\beta_2 \\
\vdots \\
\beta_p
\end{pmatrix}

\qquad

\boldsymbol \epsilon = \begin{pmatrix}
\epsilon_1 \\
\epsilon_2 \\
\vdots \\
\epsilon_n
\end{pmatrix}
```

---

#### 1.1.2. 행렬식을 이용한 회귀계수 계산

정규방정식을 이용하여 최소제곱법으로 회귀계수 벡터 $\boldsymbol \beta$의 추정치 $\hat {\boldsymbol \beta}$를 구하면 아래와 같다.

```math
\boldsymbol \epsilon = \boldsymbol y - \boldsymbol {X \beta}
```

```math
\begin{aligned}
\boldsymbol {\epsilon^2} = S &=  (\boldsymbol y - \boldsymbol {X \beta})'(\boldsymbol y - \boldsymbol {X \beta}) \\

&= \boldsymbol {y'y} - \underbrace{\boldsymbol {y'X\beta}}_{scalar값} - \underbrace{\boldsymbol {\beta'X'y}}_{scalar값} + \boldsymbol {\beta'X'X\beta} \\

\\

&= \boldsymbol {y'y} - 2\boldsymbol {\beta'X'y} + \boldsymbol {\beta'X'X\beta}\\

\end{aligned}
```

이때, $\boldsymbol {\epsilon^2}$을 최소화하기 위한 $\boldsymbol {\beta}$를 구하기 위해서는 위 식을 $\boldsymbol {\beta}$로 미분한 값이 0이 되면 된다.

```math
\begin{aligned}

\frac { \partial {\boldsymbol S} } { \partial {\boldsymbol \beta}} &= 0 - 2\boldsymbol {X'y} + \boldsymbol { X'X\beta} + \boldsymbol { \beta'X'X} \\

&= - 2\boldsymbol {X'y} + 2\boldsymbol { X'X\beta} = 0 \quad \text{(normal  equation)}\\

\end{aligned}
```

```math
\boldsymbol { X'X\beta} = \boldsymbol {X'y} \\

\\

\Rightarrow \boldsymbol {\hat \beta} = \boldsymbol {(X'X)^{-1}X'y}
```

- 회귀모형은 $\beta_n$의 값에 따라 달라진다. $\Rightarrow$ 회귀모형의 모수(parameter)는 회귀계수.

- 회귀계수를 구하는 과정에서 선형회귀분석의 5대 가정(독립변수의 독립성, 모형의 선형성, 오차 상호간의 비상관성, 오차의 정규성, 오차의 등분산성)이 필요없음 $\Rightarrow $ 선형회귀분석의 가정은 모형의 타당성을 진단하고 검정통계량을 구하는 과정에서 활용

> 참고 : 파이썬 노트북 2.1.

---

#### 1.1.3. 다변량 데이터에서 선형회귀분석이 어려운 이유1 : 정칙행렬

정규방정식을 통해 계산한 해인 $\hat {\boldsymbol \beta}$가 존재하기 위해서는 $\boldsymbol{(X'X)^{-1}}$가 존재해야 한다. 그런데 $n \ll p$인 다변량 데이터에서는 $\boldsymbol{(X'X)^{-1}}$가 존재하지 않는다. 따라서, 최소제곱법(ordinary least square, OLS)에 근거한 선형회귀분석의 해는 다변량 데이터에서는 존재하지 않는다.

- $\boldsymbol {(X'X)^{-1}}$가 존재하지 않는 이유 : 행렬 $\boldsymbol X$가 full-rank가 아니어서 $rank(\boldsymbol X) \leq n < p$이기 때문에 $(p \times p)$차원의 정방행렬인 $\boldsymbol {(X'X)}$는 $rank(\boldsymbol {(X'X)}) \leq n < p$인 정칙행렬(singular matrix)이다. 따라서, $\boldsymbol {(X'X)}$의 역행렬은 존재하지 않는다.

    - 행렬의 성질로부터 유도(정칙행렬, 행렬의 rank)

    - 직관적으로 이해하면, $(n \times m)$차원의 행렬을 $n$차원의 데이터를 $m$차원으로 변환하는 함수의 집합이라고 이해하면, 역행렬은 $(m \times n)$으로 변환된 $m$차원의 데이터를 원래의 $n$차원의 데이터로 환원하기 위한 함수의 집합 (수학적으로 $n \neq m$이면 역행렬이 존재하지 않음)

    - 정칙행렬 : $(n \times n)$ 차원의 정방행렬의 행렬식(determinant) 값이 0이거나 rank가 $n$보다 작은 경우 정칙행렬(singular matrix)이라고 한다. 정칙행렬은 $n$차원의 입력 정보를 변환하는데, 정칙행렬의 변환차원은 $n$보다 작기 때문에 변환 과정에서 $a$개($a>1$) 이상의 차원에서 정보를 손실하고, 이 때문에 변환 후의 $(n-a)$ 차원으로부터 $n$차원의 정보를 복원할 수 없다. 따라서, 정칙행렬은 역행렬이 존재하지 않는다.

    - 그런데, 다변량 데이터를 입력값으로 주고 파이썬에서 회귀분석을 돌리면 회귀계수 추정값을 내준다. 그것은 패키지에서 사용하는 방법은 역행렬을 이용한 OLS가 아니라 의사역행렬(pseudo inverse matrix)을 이용하기 때문

    - 역행렬이 존재하지 않는다는 말은 역행렬이 무수히 많다는 뜻. 의사역행렬은 무수히 많은 역행렬 중 기하학적으로 진정한 역행렬의 값에 가장 가까운 행렬을 의미.

---

#### 1.1.4. 다변량 데이터에 선형회귀분석이 어려운 이유2 : 추정통계의 불안정성

적은 수의 데이터로 모수를 추정했을 때에 나타날 수 있는 일반적인 한계로 추정량의 불안정성이 있다. 표준정규분포 $N(0, 1)$을 따르는 확률변수 $X$를 추정하기 위해 관측치가 1개인 경우와 100개인 경우의 예를 생각해보면, 동일한 관측을 10번 반복한다고 했을 때에 관측치가 1개인 경우에 $X$의 추정량이 관측치가 100개인 경위 $X$의 추정량보다 분산이 커질 수 밖에 없다. 

> 참고 : 파이썬 노트북 2.2.

비슷한 문제가 다변량 데이터의 선형회귀분석에서 나타난다. 즉, 변수의 수보다 적은 수의 관측치만을 가지고 있기 때문에 필연적으로 1개 이상의 변수는 수준 분리가 일어나지 않는다. 단순하게 모든 변수가 {0, 1}로 이루어진 범주형 변수라고 할 때, 모든 변수에 대해 0/1 수준을 교차하여 관측하기 위해 필요한 최소한의 관측치 수는 $2^p > p$인데, 이보다도 적은 수의 관측치를 가진 데이터에서는 많은 변수가 관측치는 가지고 있지만 수준에서 차별화가 되지 않는 문제에 직면한다. 따라서, 분리의 수준이 낮은 변수에 대해서는 회귀계수 추정에 필요한 데이터가 실제로는 n개가 아니라 0 또는 1개인 상황이 발생할 수 있다. 이는 앞서 본 것과 같은 1개를 관측하여 모수를 추정하는 것과 유사한 문제로, 결국 추정통계량의 불안정성이 커지게 된다.

이를 수학적으로 표현하면 아래와 같다.

회귀계수 추정량 벡터 $\boldsymbol {\hat \beta}$의 분산은 아래 과정을 거쳐 구할 수 있다.

```math
\begin{aligned}

\boldsymbol {\hat \beta} &= \boldsymbol { (X'X)^{-1}X'y } \\

&= \boldsymbol { (X'X)^{-1}X'(X\beta + \epsilon) } \\

&= \boldsymbol { \underbrace{ (X'X)^{-1}X'X}_{= I} \beta + (X'X)^{-1}X'\epsilon } \\

&= \boldsymbol { \beta + (X'X)^{-1}X'\epsilon }

\end{aligned}
```

따라서,

```math
\boldsymbol {\hat \beta - \beta} = \boldsymbol { (X'X)^{-1}X'\epsilon }
```

양변에 분산을 취하면,

```math
Var ( \boldsymbol {\hat \beta - \beta} ) = Var( 
\boldsymbol { (X'X)^{-1}X'\epsilon } )
```

```math
\begin{aligned}

\Rightarrow Var ( \boldsymbol {\hat \beta} ) &= Var( \boldsymbol { (X'X)^{-1}X'\epsilon } ) \\

&= \boldsymbol{(X'X)^{-1} X'} \boxed {Var(\boldsymbol \epsilon) }_{=\sigma^2\boldsymbol I} \boldsymbol{X(X'X)^{-1}} \\

&= \sigma^2 \boldsymbol{(X'X)^{-1}} \underbrace { \boldsymbol{X'X (X'X)^{-1}} }_{= \boldsymbol I} \\

&= \sigma^2 \boldsymbol{(X'X)^{-1}}

\end{aligned}
```

따라서, 회귀계수 추정치와 마찬가지로 $\boldsymbol{(X'X)^{-1}}$가 존재하지 않으면 분산도 존재하지 않는다. 역행렬 대신 의사역행렬을 이용하는 경우 분산을 구할 수는 있으나 의사역행렬에는 특잇값의 역수가 사용된다. 그런데 $n \ll p$인 경우에는 $p-n$개 이상의 특잇값이 0이 되고, 0이 아닌 경우에도 0에 가까운 특잇값을 많이 가지게 된다. 이 가중치 행렬을 포함하는 의사역행렬은 실제 데이터 간의 관계를 필요 이상으로 변환하게 되고 이것이 "큰 분산 = 추정통계량의 불안정성"으로 이어지게 된다.

> 의사역행렬이란? : 역행렬이 존재하지 않는 경우 다음 4가지 조건을 만족하는 유일한 행렬을 의사역행렬이라고 한다.  
> 1. $\boldsymbol {AA^+A} = \boldsymbol A$
> 2. $\boldsymbol {A^+AA^+} = \boldsymbol {A^+}$
> 3. $\boldsymbol {(AA^+)'} = \boldsymbol {AA^+}$
> 4. $\boldsymbol {(A^+A)'} = \boldsymbol {A^+A}$  
> 
> 의사역행렬을 구하기 위해서는 특잇값 분해(singular value decomposition, SVD)의 과정을 역으로 활용한다. 즉, $\boldsymbol A$를 다음과 같이 분해한다면,
> ```math
> \boldsymbol A = \boldsymbol {U \Sigma V'}
> ```
> 의사역행렬은 다음과 같이 구할 수 있다.  
> ```math
> \boldsymbol {A^+} = \boldsymbol {V \Sigma^+ U}
> ```
> 여기서 $\boldsymbol \Sigma^+$는 $\boldsymbol \Sigma$에서 0이 아닌 원소는 역수를 취하고 0인 원소는 0을 취한 대각행렬이다.

---

#### 1.1.5. 다변량 데이터에 선형회귀분석이 어려운 이유3 : 과적합

실용적인 관점에서 다변량 데이터 처리가 어려운 이유는 수학적으로 엄밀한 해의 부존재보다 과적합이다. 수준이 분리되는 변수에 대해서만 분석 모형의 적합이 이루어지기 때문에 그 결과 추정한 모형의 모수는 제한적인 범위에서만 예측 효용성을 가진다. 이 때문에 입력 데이터와 동일한 p차원의 새로운 데이터를 이용하여 반응변수를 예측하면 적합 데이터의 범위를 벗어나는 문제가 생긴다.

수학적인 예를 들면, <가로>, <세로>, <높이>를 설명변수로 가지는 3차원 데이터셋이 있다고 할 때에, <가로>에 해당하는 변수가 모두 10이라는 값만을 가지면 이 데이터의 차원은 3차원이지만 실제로 데이터를 통해 확인할 수 있는 변수의 변화는 2차원에 불과하기 때문에 <가로>가 10이 아닌 경우에 반응변수가 어떻게 변화하는지를 적절하게 예측할 수 없다.

---

### 1.2. 로지스틱 회귀분석


#### 1.2.1. 일반화 선형회귀 모형(**Generalized** Linear Model, GLM)

선형회귀분석은 반응변수(종속변수)가 실수값을 가지는 경우에 유효한 결괏값을 가진다. 그런데 반응변수가 범주형, 이산형이거나 특정 범위의 값을 가지는 경우 회귀분석 결과가 발생할 수 있다. 즉,

```math
\boldsymbol y = \boldsymbol{ X\beta } + \boldsymbol \epsilon
```

에서, $\boldsymbol \epsilon \sim N(0, \sigma^2)$인데, 정의상 $X \sim N(0, \sigma^2)$인 확률변수 $X \in (-\infty, \infty)$이다. 반면, 이분류범주형 변수의 경우 $X \in \{ 0, 1 \}$, 이산형 변수의 경우 $X \in \{ 1, 2, 3, \cdots, N\}$, 사람의 키나 나이와 같은 변수는 $X \in (0, \infty)$이기 때문에 단순선형회귀에 적합하는 경우 반응변수를 해석하기 곤란해진다. (나에게 필요한 답이 0 또는 1인데 2.1이 나온다면?)  

이러한 문제점을 해결하기 위해 반응변수가 일정한 범위를 가지는 경우, **선형예측자**($\boldsymbol { X\beta }$)에 **연결함수**를 이용하여 변환하고 반응변수에 분포 가정을 더해 회귀모형에 적합하는 분석 방법을 따르는데, 이러한 분석방법을 **일반화 선형회귀 모형(GLM)**이라고 한다. 

```math
\boldsymbol y = g( \boldsymbol{ X\beta } ) + \boldsymbol \epsilon \\

y_i \sim (\mu, \sigma^2)
```

이때, $g(\cdot)$는 정의역 내 모든 점에서 연속인 함수이다.

일반화 선형회귀의 3요소는 (1) 확률성분(반응변수의 분포 가정), (2) 체계성분(선형예측자라고도 불리우는 $\mu = \mathbb E (\boldsymbol y) = \boldsymbol {X \beta}$, 반응변수의 기댓값으로 이해하면 편함), (3) 연결함수(link function, 체계성분을 변환하는 함수)를 의미하는데, (1) 확률성분의 정의역에 따른 (3) 연결함수의 종류는 일반적으로 정해져있으며, 이를 정준연결함수(canonical link function)라고 한다. (여기서 눈여겨볼 부분은 선형회귀분석에 반응변수의 분포 가정이 필수적이지 않고, 오차항($\epsilon$)의 분포 가정이 필수적이라는 점이다. 회귀분석에서 반응변수의 분포 가정은 모수 검정이나 모형 진단 단계에 이르러야 필요하다.)

|확률성분|가우시안(정규)분포|이항분포|포아송분포|감마분포|역가우시안분포|
|------|-------------|------|-------|------|----------|
|정준연결함수($g(\mu)$)|$\mu$|$\log \frac{\mu}{1-\mu}$|$\log\mu$|$1 / \mu$|$ 1 / \mu^2$|

하지만, 해석의 편의에 따라 정준연결함수 이외에 다른 함수를 사용하기도 하며, 분포와 연결함수의 정의역이 다른 경우 제약조건을 걸어주기도 한다.

---

#### 1.2.2. 로지스틱 회귀모형

GLM 중 반응변수가 $\{ 0, 1 \}$의 범위에 있는 범주형 변수인 경우의 분석 방법을 **로지스틱 회귀모형**이라고 한다. 실수형 데이터를 범주형으로 변환하여 로지스틱 회귀모형을 적합하기도 하고, 다범주형 데이터를 이범주형 데이터로 변환하여 적합하기도 한다. 바이오 데이터를 분석하는 경우 로지스틱 회귀모형을 활용하는 경우가 많은데, 이는 실험설계의 특성상 {감염, 비감염}이나, {발병, 미발병}처럼 이범주형으로 분리할 수 있는 데이터를 많이 다루기 때문이다. 

로지스틱 회귀모형의 원리는, 앞서 설명한 일반화 선형회귀 모형의 원리를 그대로 따른다. 선형연결자를 로짓함수를 이용하여 변환하는데, 로짓함수를 로그오즈비라고도 부른다. 연결함수 변환이 이루어지면 $(0, 1)$인 반응변수의 값이 $(\log0, \log \infty)$로 바뀌는데 이 값의 범위가 $(-\infty, \infty)$와 같아진다. 이 과정을 통해 $(0, 1)$의 범위에 있는 반응변수와 $(-\infty, \infty)$의 범위에 있는 설명변수 간의 연결관계가 성립할 수 있게 된다.  

```math
y \in (0, 1) \\
\Rightarrow \frac { y } { 1 - y } \in (0, \infty) \\
\Rightarrow \log \frac { y } { 1 - y } \in (-\infty, \infty)
```

최소제곱법을 이용하여 해를 구하는 선형회귀와 달리 로지스틱 회귀모형은 **최대우도법**을 이용하여 해를 구한다. 하지만 비선형 변환함수(로짓함수)를 이용하여 $y$를 변환하는 과정을 거치기 때문에 수식을 통해서는 닫힌 해를 구할 수 없고, 알고리즘을 이용하여 수치적인 접근법을 사용하여 해를 구한다.

아래는 로지스틱 회귀모형의 해를 구하는 과정이다.

베르누이 분포를 따르는 변수 $y_i$에 대한 우도함수 $L(\boldsymbol \beta)$와 로그우도함수 $l(\boldsymbol \beta)$는 다음과 같다.

```math
\begin{aligned}

L(\boldsymbol \beta) &= \prod_{ i = 1 }^n \pi_i^{y_i} (1 - \pi_i)^{(1 - y_i)} \\

l(\boldsymbol \beta) &= \log L(\boldsymbol \beta) = \sum_{i = 1}^n \bigg[ y_i \log {\pi_i} + (1 - y_i) \log ( 1 - \pi_i) \bigg] \\

&= \sum_{i = 1}^n \bigg[ y_i \log {\pi_i} + \log ( 1 - \pi_i) - y_i \log ( 1 - \pi_i) \bigg] \\

&= \sum_{i = 1}^n \bigg[ y_i \underbrace{\log \frac {\pi_i} {1 - \pi_i}}_{= \boldsymbol {x_i' \beta}} + \underbrace{\log ( 1 - \pi_i)}_{= -\log (1 + e^{\boldsymbol {x_i' \beta}})} \bigg] \\

&= \sum_{i = 1}^n \bigg[ y_i \boldsymbol {x_i' \beta} - \log ( 1 + e^{\boldsymbol x_i' \beta}) \bigg] \\ 

&= \boldsymbol {y'X\beta} - 1' \log (1 + e^{\boldsymbol{X\beta}})

\end{aligned}
```

이제 로그우도함수의 최대값을 보장하는 $\boldsymbol \beta$를 구하기 위해 로그우도함수를 $\boldsymbol \beta$로 한 번 미분한다. (이렇게 해서 도출되는 결과값은 행렬의 형태가 되는데 이를 **자코비안 행렬**이라고 부릅니다.)

```math
\begin{aligned}

\frac {\partial l}{\partial \boldsymbol \beta } &= \boldsymbol {y X} - \boldsymbol X' \pi \\

&= \boxed{\boldsymbol X' (\boldsymbol y - \pi) = 0}_{\text{정규방정식 : 해의 유일성 조건}}

\end{aligned}
```

위 값이 최대값이 되기 위한 조건은 로그우도함수의 $\boldsymbol \beta$에 대한 2계 도함수가 0보다 큰 것이다. (함수를 벡터로 두 번 미분한 결과값은 행렬의 형태가 되는데 이를 **헤시안 행렬**이라고 부릅니다.)

```math
\begin{aligned}

\frac {\partial^2 l}{\partial \boldsymbol \beta^2 } &= \frac {\partial} {\partial \boldsymbol \beta} (- \boldsymbol X' \pi ) \\

&\begin{bmatrix}

\pi = \frac 1 {1 + e^{- \boldsymbol X \beta}} \\

\Rightarrow \frac {\partial \pi} {\partial \boldsymbol {X\beta}} = \frac {e^{- \boldsymbol X \beta}} {(1 + e^{- \boldsymbol X \beta})^2} \\

= \frac 1 {1 + e^{- \boldsymbol X \beta}} \frac {e^{- \boldsymbol X \beta}} {1 + e^{- \boldsymbol X \beta}} = \pi (1 - \pi)

\end{bmatrix}

\\


&= \boxed{- \boldsymbol {X'WX} < 0}_{\text{해의 존재성 조건}} \\


&\boldsymbol W = diag(\pi_i(1 - \pi_i))

\end{aligned}
```


---

#### 1.2.3. 로지스틱 회귀모형의 해석 : 오즈란 무엇인가?

로지스틱 회귀모형은 로짓함수를 이용하여 설명변수와 반응변수 간의 관계를 해석한다.  

적합이 끝난 로지스틱 회귀모형은 다음과 같은 다항식으로 풀어쓸 수 있다.

```math
g(\hat y_i) = \log \frac {y_i} {1 - y_i} = \beta_0 + \sum_{j = 1}^{k} \beta_j x_{ij} \\

\Rightarrow \frac {y_i} {1 - y_i} = e ^ {\beta_0 + \sum_{j = 1}^{k} \beta_j x_{ij}}

```

위 식의 좌항은 $y_i$에 대한 **오즈**이고, 우항은 자연상수($e$)를 회귀식 적합값만큼 승수배한 값이다. $x_{ik}$가 한 단위 증가할 때마다 $y_i$의 오즈비는 $e^{\beta_k}$만큼 변화한다. 만약 $\beta_k > 0$이면 오즈비는 상승하고, $\beta_k < 0$이면 오즈비는 하락한다. 오즈의 상승은 $y = 1$에 해당하는 사건이 발생할 확률이 올라가는 것으로 이해하면 된다.  

> 오즈(odds)란?
>
> 오즈는 $\frac{성공할 \ 확률}{실패할 \ 확률}$의 비율로 나타낼 수 있다. 성공 확률이 0.5인 랜덤 사건에 대해 오즈는 1이 되고, 성공확률이 커지면 오즈는 1보다 커지고, 성공확률이 작아지면 오즈는 1보다 작아진다. 만약 성공 확률이 0.2인 사건이 있다면 이 사건의 오즈는 1/4가 되고, 반대로 성공 확률이 0.8인 사건이 있다면 이 사건의 오즈는 4가 된다. 오즈를 통해 $(0, 1)$인 확률의 개념을 $(0, \infty)$의 범위로 변환하는 것인데, 이러한 범위의 변환은 직관적으로 잘 와닿지 않는다. 그 이유 중 하나는 0.5를 기준으로 양극단 사이에서 균일한 범위에서 변하는 "성공 확률"이라는 개념을 이용하면 발생 가능성의 변화가 훨씬 더 직관적으로 와닿는 반면, 오즈가 1에서 1.5로 바뀌는 것과 0.5로 바뀌는 것 사이의 확률변화는 직관적으로 와닿지 않기 때문이다. 즉, 확률의 변화량이 오즈의 변화량으로 1:1 스케일로 매칭되지 않는다. (오즈가 1.5로 변화하기 위해 성공확률은 0.5에서 $5/7$로 늘어야 하고, 0.5로 변화하기 위해서 성공확률은 0.5에서 $1/3$으로 줄어야 한다. / 한편, 두 집단의 오즈를 비교하기 위해서는 **오즈비**라는 개념을 이용하는데, 이는 $\frac{비교군의 \ 오즈}{대조군의 \ 오즈}$로 나타낼 수 있다.)
>
> 그럼에도 오즈를 사용하는 이유는 해석의 용이성과 수학적 간결성 때문이다. (1) 로지스틱 회귀모형 해석 방법에서 알 수 있듯이, 반응변수의 증가분을 오즈비로 해석하면 두 변수 간의 관계를 간결하게 설명할 수 있다. 특(2) 의료 데이터 연구 방법 중 케이스 컨트롤(case-control) 연구 방법이 있는데, 실험설계에 가까운 다른 연구들과 달리 케이스 컨트롤 연구 방법은 연구의 대상이 되는 반응변수를 기준으로 데이터를 수집한다. 따라서 설명변수 $\rightarrow$ 반응변수로 이어지는 인과관계를 설명하기 위한 수리적인 근거가 부족하나, 반응변수를 기준으로 두 사례의 오즈비를 구해서 이를 기준으로 해석하면 두 변수의 관계를 수리적으로 해석할 수 있게 된다. (3) 의료 데이터 연구에서 약제 투여군의 효과를 비교하는 지표로 위험비(rate ratio, RR)가 있다. 이는 투약군과 위약군 간의 사건발생률의 비율 차이인데, 투약의 효과를 가장 잘 보여주는 직접적인 평가 지표이다. 그런데 사건발생률이 극도로 낮은 경우 오즈비는 RR에 근사하게 된다. 이 때문에 감염률, 감염사망률 등 $p$가 낮은 질병을 대상으로 연구하는 경우 오즈비를 RR의 대체지표로 사용한다. 

---

#### 1.2.4. 다변량 데이터 분석 방법으로서 로지스틱 회귀모형

다변량 데이터를 분석할 때에 로지스틱 회귀모형을 사용하는 경우 두 가지 측면에서 선형회귀보다 이득이 있다. 

첫째, 로지스틱 회귀모형은 해를 구하는 과정에서 오차항의 정규성과 등분산성 가정을 이용하지 않는다. 이 때문에 $\boldsymbol {X'X}$의 성질과 관계없이 해를 구할 수 있다. 2.2에서 설명한 과정을 통해서는 모형의 해 $\boldsymbol {\hat \beta}$를 구할 수 없다. 그 이유는 $\boldsymbol X'(\boldsymbol y - \pi) = 0$이 되는 $\boldsymbol \beta$값을 찾아야 하는데, $\pi = f(\boldsymbol {X'\beta})$의 형태로 다양한 차원에서 $\boldsymbol \beta$를 포함하고 있어 $\beta$에 대해 수식을 정리할 수 없기 때문이다. 따라서, 해를 구하기 위해서 **경사하강법**을 이용한 반복알고리즘에 값을 대입한 뒤, 수렴성이 확인되면 미리 설정한 임계값의 범위 내에서 해를 추정하는 방식의 수치적 접근법으로 해를 구한다. 따라서, 선형회귀가 가지는 약점 한 가지에서 자유롭다.

둘째, 앞서 설명한 것처럼 수치적 방법으로 해를 구하기 때문에 해를 구하기 힘든 불능문제에서 어느 정도 자유롭다. 2.2에서 설명한 것과 같이 로지스틱 회귀모형의 해가 유일하게 존재하기 위해서는 정규방정식의 조건과 헤시안 행렬의 조건을 충족해야 하는데, 헤시안 조건만 충족하면 정규방정식 조건을 충족하지 않더라도 해를 구할 수 있다. 유일성 조건을 충족하지 않으면 유한한 $\boldsymbol {\hat \beta}$가 존재하지만 어떤 $\boldsymbol {\hat \beta}$를 대입하더라도 $\boldsymbol y = \boldsymbol {X' \hat \beta}$값은 유일해진다. (이 경우 $\boldsymbol {\hat \beta}$의 추정값은 의사역행렬을 이용하여 구합니다.)

셋째, 반응변수를 단순화함으로써 수준의 부족 문제를 **어느 정도는** 보완할 수 있다. 변수가 실수 범위에 존재하는 것보다는 이변수 범위에 존재하는 것이 한 수준에 존재하는 데이터의 관측치 수가 많아지게 할 수 있기 때문이다. 즉, $y = 1, 2, \cdots, 10$일 때에 각각의 수준에 맞춰 관측치가 존재하기 위해서는 최소 10개의 관측치가 있어야 하지만 $y = 0, 1$일 때에는 수준별 관측치가 존재하기 위해서는 최소 2개의 관측치만 있으면 된다.

---

#### 1.2.5. 다변량 데이터 분석에서 로지스틱 회귀모형의 한계 : 해의 유일성이 보장되지 않음

로지스틱 회귀모형은 최대우도법을 통해 해($\boldsymbol {\hat \beta}$)를 구하는데, 위에 설명한 것과 같이 분석기법 자체에서 해의 존재성과 유일성이 보장되지 않는다. 존재성 보장 조건은 $\boldsymbol {X'WX} > 0$인데, $n \ll p$이면 $\boldsymbol X'X$는 정칙행렬이다. 이 경우, $\boldsymbol X'X \ge 0$이 되어 해의 유일성이 보장되지 않는다. 따라서, 회귀계수 추정이 불안정해진다. 

---


#### 1.2.6. 다변량 데이터 분석에서 로지스틱 회귀모형의 한계 : 완전분리

다변량 데이터가 가지는 또다른 약점은 **완전분리**가 발생할 가능성이 높아진다는 점이다. 완전분리란, 설명변수 $X$와 이항반응변수 $Y$가 **초평면**을 통해 완전히 분리할 수 있는 상태를 의미한다. 직관적으로는 산점도를 그렸을 때 반응변수가 설명변수를 기준으로 예외없이 갈라지는 상황을 의미한다. **초평면**상에 점이 존재하지 않는 완전분리와 점이 존재하는 준완전분리로 구분하기도 한다. 이를 수식으로 표현하면 아래와 같다.

```math
\begin{cases}

x_i'\gamma \ge 1, \text{if } y_i = 1, \\

x_i'\gamma \le -1, \text{if } y_i = 0

\end{cases}
```

완전분리 상태에서는 로지스틱 회귀모형의 해가 도출되지 않는다. 그 이유를 직관적으로 설명하면, 해를 근사하기 위한 경사하강법의 한계와 관련이 있다. 경사하강법을 반복하는 알고리즘에서는 로그우도함수를 $\beta$값이 수렴범위에 들어올 때까지 거듭미분하게 되는데, 완전분리 조건에서는 $x_i' \gamma < 0$인 값들이 $y_i = 0$과 결합하여 모두 없어지기 때문에 미분을 거듭할수록 값이 커진다. 따라서 알고리즘을 반복했을 때에 특정 범위 안으로 값이 모이지 않고 발산하게 된다. (수학적 해설은 생략)

그런데, $n \ll p$인 다변량 데이터 하에서는 1.4에서 설명한 것과 같이 변수의 수보다 관측치의 수가 작아져 완전분리가 발생할 가능성이 높아진다. 완전분리가 있는 데이터을 로지스틱 회귀모형에 적합하면 보정 알고리즘을 거쳐 수렴성이 보장되도록 조건을 만들어 회귀계수를 추정하지만 경고 메시지가 나온다. 

> 참고 : 파이썬 노트북 2.3

그 밖에 선형회귀분석이 가지는 약점인 다중공선성, 과다적합 문제는 동일하게 남는다. 

---

### 1.3. 결론

전술한 많은 약점과 한계 때문에 회귀분석은 다변량 데이터를 다루는 데에 적합한 분석 방법은 아니다. 하지만, 선형회귀모형에 수학적 변환을 가해 데이터의 특성에 맞게 회귀분석을 발전시키는 일련의 과정은 통계적 이론에 기반한 분석 방법뿐만 아니라 머신러닝에 기반하고 있는 분석 방법까지도 공통적으로 공유하고 있는 원리이다. 이번 회차에서는 선형회귀모형의 파생 분석 방법으로써 일반화 회귀모형, 그 중에서도 로지스틱 회귀모형의 원리와 한계를 통해 이러한 전개 과정을 살펴봤다. 다음 시간에는 다변량 데이터가 가지는 특성을 극복하며 회귀분석을 진행할 수 있는 다양한 분석 방법을 살펴보겠다.