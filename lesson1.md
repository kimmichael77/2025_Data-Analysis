## 1. 강의계획서 설명

- 전반기에는 다변량데이터 분석, 후반기에는 시계열데이터 분석에 대해 강의

- 통계학 이론에 기반한 회귀분석의 관점에서 다변량데이터 분석에 어떤 측면에서 한계가 있는지를 확인

- 컴퓨터공학(computer science, CS) 기반의 분석 방법이 회귀분석이나 이론에 기반한 분석 방법이 놓친 부분을 어떻게 메꾸고 있는지를 이해하고,

- 두 분석 방법의 장단점을 이해함으로써 실전 데이터 분석에서 적절한 분석 기법을 설계할 수 있는 능력을 배양하는 것이 수업의 목표

- 주요 분석방법에 따라 수업을 2주 단위로 구성

- 1주차에는 주된 분석방법의 개념, 수학적인 배경, 결과 통계량 해석 방법, 예제 코드(파이썬)에 대해서 공부하고,

- 2주차에는 각 분석방법에서 파생되었거나 연결되어있는 분석방법에 대해 설명하는 방식으로 수업 진행

- 수학 및 코드 이해 및 숙달 정도에 따라 수업 내용의 깊이를 유연하게 조절할 예정

- 매주 수업자료와 코드자료를 [깃허브](https://github.com/esoterikosQ/2025DataAlgorithm.git)를 통해 배포할 예정

- 매주 주차별 수업자료를 읽고, 코드자료에 주석을 달아 과제로 제출하는 과제 수행
    
    - 수업 시작 전까지 이메일(seunggyu.bak@gmail.com)로 제출

- 중간과제는 10주차(군집분석 수업 이후), 기말과제는 16주차(학기 종료 전)까지 제출하는 것을 원칙으로 하되, 가급적 주차별 과제를 수행하면서 마감기한 이전에 언제든지 제출할 것을 권장

> 참고 : 강의계획서

---

### 1.2. 강의개관 : 다변량 분석

- 다변량 데이터 분석은 회귀분석, 주성분분석, 군집분석 순으로 진행

- 다변량 데이터의 특성으로 인해 생기는 회귀분석의 한계를 이해하고, 이를 보완하기 위해서 고안된 분석 방법이 다변량 데이터의 특성을 어떤 방식으로 다루고 있는지를 이해하고, 

- 또한, 회귀, 주성분, 군집분석의 한계를 이해하고 이러한 한계를 보완하기 위해 파생된 분석 방법이 어떤 것들이 있는지를 학습하는 것이 목표

#### 1.2.1. 회귀분석

- 다변량 데이터가 가지는 $ n \ll p$ 문제가 최소제곱법(OLS)에 기반한 회귀분석에 어떤 문제를 일으키는가?

- 이에 대응하기 위해 일반화선형회귀, 변수선택, 정규화회귀, 부분최소제곱회귀 등 회귀분석 계열의 다른 분석방법을 사용했을 때에 어떤 부분에서 장/단점이 있는가?

#### 1.2.2. 주성분분석

- $n \ll p$ 문제를 극복하는 방안의 일환으로 $p$를 축소하는 측면에서 주성분분석은 어떤 원리를 가지고 어떤 방식으로 활용될 수 있는가?

- $p$를 축소하는 점에 초점이 맞춰진 인자분석, 커널주성분분석, 판별분석, t-SNE(t분포 확률 임베딩)의 원리와 장단점을 PCA와 비교하여 이해

#### 1.2.3. 군집분석

- '거리'의 개념과 비지도학습 방법으로서 '군집화'가 $n \ll p$ 데이터 처리에 어떤 강점을 가질 수 있는가?

- 군집화 알고리즘 중 위계적 군집화, K-평균 군집화, DBSCAN의 원리와 장단점을 이해

- 군집화에 초점을 둔 분석방법인 자기조직화지도(SOM), 서포트 벡터 머신(SVM), UMAP의 원리와 장단점을 이해

### 1.3. 강의개관 : 시계열 분석

- 시계열 데이터의 특성(t라는 요소)과 이에 대한 수리적 접근법으로서 ARIMA 계열의 분석 방법이 취하고 있는 분석의 원리는 어떤 것인가?

- '선형 필터를 이용한 분해'가 가지는 장단점은 무엇인가?

- 신경망 모형의 종류와 원리에 대해 이해 : CNN, RNN, LSTM을 중심으로

- 신경망을 이용한 시계열 분석 예제 소개

- t개념의 확장 : 시계열 데이터와 자연어 데이터가 어떤 측면에서 유사성이 있는가?

#### 1.4. 강의개관 : 주파수 분석 

- 주파수 분석의 개념과 수학적 원리에 대해 이해

- 시계열 분석과 다변량 분석에 주파수 분석을 활용할 수 있는가?


--- 


## 2. 데이터 분석 이해도 평가

- 본격적인 수업 진행에 앞서 수강생들의 데이터 분석에 대한 이해도를 평가합니다.

- 향후 수업의 내용과 진행 방향을 설정하기 위한 간단한 테스트로, 학생 개개인의 평가에는 아무런 영향이 없습니다.

### 2.1. 아래의 모형을 설명하시오.

```math
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon \\

\\

\epsilon \sim N(0, \sigma^2)
```

- 반응변수는 무엇인가?

- 설명변수는 무엇인가?

- 위 모형의 모수(parameter)는 무엇인가?

- 위 모형의 가정은 무엇인가?

- 위 모형의 해를 구하는 방법은 무엇인가?

### 2.2. 2.1의 모형과 비교하여 아래의 모형을 설명하시오.

```math
\boldsymbol y = \boldsymbol {X\beta} + \boldsymbol \epsilon \\

\boldsymbol y : (n \times 1), \ \boldsymbol X : (n \times 4), \ \boldsymbol \epsilon : (n \times 1), \ \boldsymbol \beta : (? \times 1)
```

- 2.1. 모형과 어떤 점에서 차이가 있는가?

- 위 모형의 해를 구하는 방법은 무엇인가?

- 위 모형의 해가 2.1.의 해와 동일해지기 위한 조건은?

- ?에 들어갈 숫자는 어떤 것인가?

- $\boldsymbol X$의 명칭은?


### 2.3. 다음의 코드에 대해 설명하시오.

```python
import numpy as np
import pandas as pd
from sklearn.datasets import load_diabetes
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import summary_table

diabetes = load_diabetes()
X = diabetes.data
y = diabetes.target
model_sm = sm.OLS(y, X)
results_sm = model_sm.fit()
print(results_sm.summary())
```

- 위 코드는 무엇을 수행하는 코드인가?

- 위 코드 수행과 무관하게 호출한, 불필요한 패키지의 개수는?

- 위 코드에서 2.2.의 해를 구하는 것과 직결되는 부분은?

- (*) 위 코드를 수행했을 때에 2.1.에서 찾고자 하는 모수를 찾을 수 있는가? 만일 그렇지 않다면 그 이유는?

---

## 3. 데이터 분석 절차 설명

- 이하는 데이터 분석을 위해 수행하는 표준적인 절차를 설명했습니다.

- 데이터 분석을 하는 절차와 순서는 분석가 개인의 성향에 따라 크게 달라지기 때문에 아래의 절차는 예시로 이해하시고, 만약 본인 고유의 분석 스타일이 확립되지 않은 경우에만 참고용으로 활용하시기 바랍니다.


### 3.1. 준비작업

- 데이터 분석에 필요한 환경 및 데이터를 갖추는 작업

- 기술적인 환경 설정과 패키지 로딩, 데이터 로딩이 여기에 포함

- 좀 더 근본적으로 안정적으로 분석을 수행할 수 있는 컴퓨팅 환경의 설정까지도 이 범주에 속함(conda, venv, docker, jupyter notebook, IDE, python, pip, 패키지 설치 등)

### 3.2. 탐색 및 전처리

- 데이터의 구조, 변수의 속성 및 성질을 확인하고 분석에 적합한 형태로 전처리하는 작업

- 통상 <데이터 구조 확인 및 변수 속성 확인 $\rightarrow$ 평균, 중간값, 분위수, 분산 등 요약통계량 확인 $\rightarrow$ 히스토그램, 산점도 확인 $\rightarrow$ 상관계수 확인>과 같이 피상적 정보 확인에서 심층적 정보 탐색으로 이어지는 방식으로 진행

- 분석하고자 하는 방식에 맞춰서 데이터의 크기, 자료형을 맞추는 전처리 작업이 뒤따름. 

- 전처리 과정은 이후 과정에서 원하는 결과가 나오지 않거나 오류가 나는 등의 이유 때문에 분석 방법을 수정하는 경우 수시로 반복되는 과정

### 3.3. 분석

- 계획한 방법에 따라서 분석 수행

- 분석 역시 한 번에 끝나는 과정이 아니라 이후 진단/평가를 거쳐 재차 분석하는 경우가 훨씬 많음. 심지어는 최초 계획했던 분석과 완전히 다른 분석을 다시 수행해야 하는 경우도 비일비재

### 3.4. 진단/평가

- 분석 방법에 따라 도출한 결과 통계량을 해석하는 과정. 결과 통계량 시각화가 수반되는 경우가 많음.

- 데이터 분석의 최초 목표를 달성했는지 여부가 평가의 기준

- 분석 방법 자체에 내재된 진단 방법에 따라서 분석이 오류없이 수행되었는지를 판단하는 과정까지를 포함

- 일반적으로 절대적인 평가기준은 없고, 다수의 분석 모델의 결과 통계량을 비교하여 의미를 이끌어내거나 가장 우월한 모델을 선택하는 방식으로 진행

### 3.5. 결과 보고

- 최초 수립한 분석의 목표에 맞춰 분석 과정을 평가

- 다양한 방식으로 결과보고서를 작성. 이를 위해 다양한 툴(태블로나 QGIS와 같은 시각화 솔루션, html, java, markdown과 같은 결과물 작성 기술, 기타 파이썬, R 등 언어환경에 기반한 다양한 시각화 패키지에 대한 숙달이 수반되어야 함)


## 4. 수업 진행방식 설명

### 4.1. 사전에 제시하는 강의자료를 스스로 예습

- 특별한 사정이 없는 한 강의일로부터 최소 4일 이전까지 다음 차시 강의자료를 업로드할 예정

- 특별한 사정이 있더라도 이틀 전까지는 강의자료를 업로드할 예정

### 4.2. 수업시간에는 강의자료 중에서 특별히 어려운 부분을 강조하여 설명

- 수학적인 배경지식이 적을 것이라는 가정 하에 수학적인 설명과 의미 도출에 초점을 둘 예정

- 코딩과 사례 설명의 비중을 늘리기를 원하는 수강생이 많으면 이 부분은 조정이 가능

### 4.3. 학생들이 스스로 예습하는 과정에서 해결할 수 없었던 문제를 질문/답변/토론하는 시간으로 활용

- 고민하는 과정을 거쳤다면 "이 부분은 도저히 이해가 안 갑니다"라고 질문해도 무방

- 코드를 효율화할 수 있는 방법이나 다른 패키지를 소개하는 과정, 코드를 짜는 노하우에 대해서도 토론할 예정

- 생성형AI를 이용한 학습과 코딩을 적극 권장. 과제 역시 생성형AI를 적극 활용하여 수행할 것을 권장

- 다만, 생성형AI는 요구사항에 100% 부합하는 결과물을 내놓지 않는다는 점을 항상 유념하고, 반드시 코드 전반을 검토하고 고민하는 과정을 거쳐야 내 실력으로 이어짐.

### 4.4. 실제 수업은 쉬는시간 없이 2시간 전후로 진행

- 야간 수업이라는 점과 수강생 중 비전업으로 학습하는 인원이 포함된 점을 고려

- 예정된 수업의 목표 달성을 위해 과제 수행에 많은 공을 들여주기를 당부

- 진짜 실력은 고민 + 질문을 통해 키워짐